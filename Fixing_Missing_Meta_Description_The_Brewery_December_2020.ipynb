{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Fixing Missing Meta Description - The Brewery - December 2020",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buZ-c4fi8gcC"
      },
      "source": [
        "# Generating Missing Meta Descriptions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eTmScmc9YgQ"
      },
      "source": [
        "You can read the blog post here: https://wordlift.io/blog/en/write-meta-descriptions-bert/\n",
        "\n",
        "## Importing and installing the libraries we need\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OdlLmidEJ7T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d844134-c0c0-4f6a-aa80-01b8b843eba2"
      },
      "source": [
        "!pip install -U git+https://github.com/adbar/trafilatura.git\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "!pip install spacy==2.1.3\n",
        "!pip install transformers\n",
        "#MK---------\n",
        "#!pip install bert-extractive-summarizer==0.2.*\n",
        "\n",
        "#MK\n",
        "!pip install bert-extractive-summarizer\n",
        "#MK\n",
        "!pip install neuralcoref\n",
        "\n",
        "#MK\n",
        "!pip install awscli awsebcli --upgrade\n",
        "\n",
        "#MK\n",
        "!pip install urllib3==1.25.10\n",
        "\n",
        "#MK\n",
        "!pip install urllib3==1.21.1\n",
        "#MK\n",
        "!pip install urllib3==1.24.1\n",
        "#MK\n",
        "!pip install urllib3==1.25.4\n",
        "\n",
        "#MK\n",
        "#MK(i added this LOC) !pip install boto3 --upgrade\n",
        "\n",
        "#MK\n",
        "!pip install botocore\n",
        "\n",
        "#MK\n",
        "!pip install botocore==1.17\n",
        "\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import requests, sys\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import trafilatura\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/adbar/trafilatura.git\n",
            "  Cloning https://github.com/adbar/trafilatura.git to /tmp/pip-req-build-75e4u2eu\n",
            "  Running command git clone -q https://github.com/adbar/trafilatura.git /tmp/pip-req-build-75e4u2eu\n",
            "Requirement already satisfied, skipping upgrade: courlan>=0.2.3 in /usr/local/lib/python3.6/dist-packages (from trafilatura==0.6.1) (0.2.3)\n",
            "Requirement already satisfied, skipping upgrade: htmldate>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from trafilatura==0.6.1) (0.7.2)\n",
            "Requirement already satisfied, skipping upgrade: justext>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from trafilatura==0.6.1) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: readability-lxml>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from trafilatura==0.6.1) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<2,>=1.25 in /usr/local/lib/python3.6/dist-packages (from trafilatura==0.6.1) (1.25.4)\n",
            "Requirement already satisfied, skipping upgrade: lxml>=4.6.2 in /usr/local/lib/python3.6/dist-packages (from trafilatura==0.6.1) (4.6.2)\n",
            "Requirement already satisfied, skipping upgrade: chardet>=3.0.4 in /usr/local/lib/python3.6/dist-packages (from trafilatura==0.6.1) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from courlan>=0.2.3->trafilatura==0.6.1) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tldextract in /usr/local/lib/python3.6/dist-packages (from courlan>=0.2.3->trafilatura==0.6.1) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.8.1 in /usr/local/lib/python3.6/dist-packages (from htmldate>=0.7.2->trafilatura==0.6.1) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cssselect in /usr/local/lib/python3.6/dist-packages (from readability-lxml>=0.8.1->trafilatura==0.6.1) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->courlan>=0.2.3->trafilatura==0.6.1) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->courlan>=0.2.3->trafilatura==0.6.1) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: requests-file>=1.4 in /usr/local/lib/python3.6/dist-packages (from tldextract->courlan>=0.2.3->trafilatura==0.6.1) (1.5.1)\n",
            "Requirement already satisfied, skipping upgrade: filelock>=3.0.8 in /usr/local/lib/python3.6/dist-packages (from tldextract->courlan>=0.2.3->trafilatura==0.6.1) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.8.1->htmldate>=0.7.2->trafilatura==0.6.1) (1.15.0)\n",
            "Building wheels for collected packages: trafilatura\n",
            "  Building wheel for trafilatura (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trafilatura: filename=trafilatura-0.6.1-cp36-none-any.whl size=166664 sha256=3b8f5cddc2c7d399c082d76c74aad740c85cad6e458850e610372b25c47639fa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-myfej3fm/wheels/78/ed/6b/4e1987f9c618c11c418e0d7a59ec08310dd900c3c86cd79ceb\n",
            "Successfully built trafilatura\n",
            "Installing collected packages: trafilatura\n",
            "  Found existing installation: trafilatura 0.6.1\n",
            "    Uninstalling trafilatura-0.6.1:\n",
            "      Successfully uninstalled trafilatura-0.6.1\n",
            "Successfully installed trafilatura-0.6.1\n",
            "TensorFlow 1.x selected.\n",
            "Requirement already satisfied: spacy==2.1.3 in /usr/local/lib/python3.6/dist-packages (2.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (2.0.5)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (0.9.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (1.0.5)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (0.2.4)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (2.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (1.19.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (0.8.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (7.0.8)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (1.25.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.3) (4.41.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.25.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: bert-extractive-summarizer in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (from bert-extractive-summarizer) (4.1.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from bert-extractive-summarizer) (2.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from bert-extractive-summarizer) (0.22.2.post1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (0.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (20.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (1.19.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (4.41.1)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (0.2.4)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (2.0.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (2.6.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (2.0.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.0.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->bert-extractive-summarizer) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->bert-extractive-summarizer) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->bert-extractive-summarizer) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->bert-extractive-summarizer) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->bert-extractive-summarizer) (1.25.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (1.15.0)\n",
            "Requirement already satisfied: neuralcoref in /usr/local/lib/python3.6/dist-packages (4.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.1.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.16.41)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.19.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.5)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Collecting botocore<1.20.0,>=1.19.41\n",
            "  Using cached https://files.pythonhosted.org/packages/b9/69/eecc498592e2ee9a300037881b38637358dbddd5211d2af061c8b177abe4/botocore-1.19.41-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.3.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.25.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.41->boto3->neuralcoref) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.41->boto3->neuralcoref) (1.15.0)\n",
            "\u001b[31mERROR: awsebcli 3.19.2 has requirement PyYAML<5.4,>=5.3.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "Installing collected packages: botocore\n",
            "  Found existing installation: botocore 1.17.0\n",
            "    Uninstalling botocore-1.17.0:\n",
            "      Successfully uninstalled botocore-1.17.0\n",
            "Successfully installed botocore-1.19.41\n",
            "Requirement already up-to-date: awscli in /usr/local/lib/python3.6/dist-packages (1.18.201)\n",
            "Requirement already up-to-date: awsebcli in /usr/local/lib/python3.6/dist-packages (3.19.2)\n",
            "Requirement already satisfied, skipping upgrade: colorama<0.4.4,>=0.2.5; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from awscli) (0.4.3)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from awscli) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: botocore==1.19.41 in /usr/local/lib/python3.6/dist-packages (from awscli) (1.19.41)\n",
            "Requirement already satisfied, skipping upgrade: rsa<=4.5.0,>=3.1.2; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from awscli) (4.5)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML<5.4,>=3.10; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from awscli) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: future<0.17.0,>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pathspec==0.5.9 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (0.5.9)\n",
            "Requirement already satisfied, skipping upgrade: cement==2.8.2 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: six<=1.15.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: docker-compose<1.26.0,>=1.25.2 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (1.25.5)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth<0.2.0,>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (0.1.9)\n",
            "Requirement already satisfied, skipping upgrade: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.26,>=1.25.4 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (1.25.4)\n",
            "Requirement already satisfied, skipping upgrade: blessed>=1.9.5 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (1.17.12)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=20.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: semantic-version==2.5.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<=2.24,>=2.20.1 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.19.41->awscli) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=4.5.0,>=3.1.2; python_version != \"3.4\"->awscli) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: cached-property<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: dockerpty<1,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: texttable<2,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: docker[ssh]<5,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema<4,>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: websocket-client<1,>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (0.57.0)\n",
            "Requirement already satisfied, skipping upgrade: docopt<1,>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (0.6.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<=2.24,>=2.20.1->awsebcli) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<=2.24,>=2.20.1->awsebcli) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<=2.24,>=2.20.1->awsebcli) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: paramiko>=2.4.2; extra == \"ssh\" in /usr/local/lib/python3.6/dist-packages (from docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (2.7.2)\n",
            "Requirement already satisfied, skipping upgrade: bcrypt>=3.1.3 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (3.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cryptography>=2.5 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (3.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pynacl>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.1 in /usr/local/lib/python3.6/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (1.14.4)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (2.20)\n",
            "Collecting urllib3==1.25.10\n",
            "  Using cached https://files.pythonhosted.org/packages/9f/f0/a391d1463ebb1b233795cabfc0ef38d3db4442339de68f847026199e69d7/urllib3-1.25.10-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.2 has requirement PyYAML<5.4,>=5.3.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.25.4\n",
            "    Uninstalling urllib3-1.25.4:\n",
            "      Successfully uninstalled urllib3-1.25.4\n",
            "Successfully installed urllib3-1.25.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting urllib3==1.21.1\n",
            "  Using cached https://files.pythonhosted.org/packages/24/53/f397db567de0aa0e81b211d81c13c41a779f14893e42189cf5bdb97611b2/urllib3-1.21.1-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: trafilatura 0.6.1 has requirement urllib3<2,>=1.25, but you'll have urllib3 1.21.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.19.41 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.21.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.2 has requirement PyYAML<5.4,>=5.3.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.2 has requirement urllib3<1.26,>=1.25.4, but you'll have urllib3 1.21.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.25.10\n",
            "    Uninstalling urllib3-1.25.10:\n",
            "      Successfully uninstalled urllib3-1.25.10\n",
            "Successfully installed urllib3-1.21.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting urllib3==1.24.1\n",
            "  Using cached https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: trafilatura 0.6.1 has requirement urllib3<2,>=1.25, but you'll have urllib3 1.24.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.19.41 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.2 has requirement PyYAML<5.4,>=5.3.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.2 has requirement urllib3<1.26,>=1.25.4, but you'll have urllib3 1.24.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.21.1\n",
            "    Uninstalling urllib3-1.21.1:\n",
            "      Successfully uninstalled urllib3-1.21.1\n",
            "Successfully installed urllib3-1.24.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting urllib3==1.25.4\n",
            "  Using cached https://files.pythonhosted.org/packages/91/0d/7777358f672a14b7ae0dfcd29f949f409f913e0578190d6bfa68eb55864b/urllib3-1.25.4-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.2 has requirement PyYAML<5.4,>=5.3.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.24.1\n",
            "    Uninstalling urllib3-1.24.1:\n",
            "      Successfully uninstalled urllib3-1.24.1\n",
            "Successfully installed urllib3-1.25.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: botocore in /usr/local/lib/python3.6/dist-packages (1.19.41)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore) (1.25.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.15.0)\n",
            "Collecting botocore==1.17\n",
            "  Using cached https://files.pythonhosted.org/packages/b8/bc/8a6e8b8f062da15deb79ef3ceb846b0654c0640addf491c7984c5a056416/botocore-1.17.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.17) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.17) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore==1.17) (1.25.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore==1.17) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.17) (1.15.0)\n",
            "\u001b[31mERROR: boto3 1.16.41 has requirement botocore<1.20.0,>=1.19.41, but you'll have botocore 1.17.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.2 has requirement botocore<1.20.0,>=1.19.0, but you'll have botocore 1.17.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.2 has requirement PyYAML<5.4,>=5.3.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awscli 1.18.201 has requirement botocore==1.19.41, but you'll have botocore 1.17.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: botocore\n",
            "  Found existing installation: botocore 1.19.41\n",
            "    Uninstalling botocore-1.19.41:\n",
            "      Successfully uninstalled botocore-1.19.41\n",
            "Successfully installed botocore-1.17.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t41cZ9efGGo5"
      },
      "source": [
        "## Downloading crawl data from Google Sheet \n",
        "\n",
        "The script uses the _url` CSV file generated with **WooRank Crawler** (or alternatively the data from **Screaming Frog**) that provides the list of URLs and the information of where the MD is missing.  \n",
        "\n",
        "The data has been imported into Google Sheet so that we can inspect it. Change the URL below after publishing your CSV:\n",
        "\n",
        "\n",
        "> 1. Open file from \"My Drive\" or \"Upload\"\n",
        "2. File -> Publish to the web -> \"Sheet name\" option and \"csv\" option\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjseHMCmsp8C"
      },
      "source": [
        "### Using WooRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag1C6HlcHszA"
      },
      "source": [
        "# Download the list of URLs from Google Docs (file generated with WooRank) \n",
        "# Replace the following with a crawl from your favorite website that you have published on Google Drive\n",
        "!wget 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQHEO3j6o59pCyfbXMEEi7zwTJGoNT-_RaXB8oL0Pg1wL1Y1dqFd5M4g_7ZMPMdIo0X8tuQCzeXuRsp/pub?gid=1712919487&single=true&output=csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsF8H4sdIIfI"
      },
      "source": [
        "#### Creating a Pandas DataFrame from WooRank data\n",
        "\n",
        "\n",
        "Following the file structure generated using the WooRank's crawler, we will use the following columns:\n",
        "\n",
        "- *url* (`cols='0'` | `url`), \n",
        "- *status code* (`cols='5'` | `status`),\n",
        "- *page type* (`cols='8'` | `parent_type`)\n",
        "- *internal or esternal* (`cols='12'` | `from_internal`)\n",
        "- *position* (`cols='38'` | `position`)\n",
        "- *meta description lenght in px* (`cols='46'` | `description_len_px`)\n",
        "\n",
        "We will then use *http status* to focus our analysis only to urls responding with `HTTP 200`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ntyfjL3H7-b"
      },
      "source": [
        "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQHEO3j6o59pCyfbXMEEi7zwTJGoNT-_RaXB8oL0Pg1wL1Y1dqFd5M4g_7ZMPMdIo0X8tuQCzeXuRsp/pub?gid=1712919487&single=true&output=csv', # Update the string here to change the file\n",
        "                 #usecols=[0,5,8,12,38,46],  \n",
        "                 usecols=[0,2,11],\n",
        "                 header=0,\n",
        "                 encoding=\"utf-8-sig\" )\n",
        "\n",
        "print(\"we have a total of:\", len(df), \" urls\")\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atX3kesIyEBP"
      },
      "source": [
        "#### Finding all URLs where meta description are missing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCxyE4V1xvEs"
      },
      "source": [
        "# Keep all rows representing a page with status = 200, with md either null or 0, from the English blog and with Position < 15 \n",
        " \n",
        "#df = df[(df['from_internal'] != 'no') & (df['status'] == 200) & (df['parent_type'] == 'PAGE') & ((df['description_len_px'].isnull()) | (df['description_len_px']== 0)) & (df['url'].str.contains(\"blog/it\")) & (df['position'] < 15) & (df['position'] > 3)] # Use this with WooRank\n",
        "\n",
        "df = df[(df['Status Code'] == 200) & \n",
        "        ((df['Meta Description 1 Pixel Width'].isnull()) | (df['Meta Description 1 Pixel Width']== 0)) \n",
        "        ] # Use this with WooRank\n",
        "\n",
        "print(\"we have to process:\", len(df), \" urls\")\n",
        "\n",
        "# Reindex df\n",
        "df.index = range(len(df.index))\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBcyTfZ4tVJ8"
      },
      "source": [
        "### Using Screaming Frog"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JALL291GtZap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ba1fc7-6890-4600-e05e-5d63b1cf213b"
      },
      "source": [
        "# Download the list of URLs from Google Docs (file generated with Screaming Frog SEO Spider) \n",
        "# Replace the following with a crawl from your favorite website that you have published on Google Drive\n",
        "\n",
        "!wget 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRPJMu_aen9BTSuW0tDJsbA07ZJBzJHeF2uM8Ov-GKhrT1rb6k0Nup98qHg4p0RpZaTzVaLkhc1DDY0/pub?gid=951755148&single=true&output=csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-22 16:41:35--  https://docs.google.com/spreadsheets/d/e/2PACX-1vRPJMu_aen9BTSuW0tDJsbA07ZJBzJHeF2uM8Ov-GKhrT1rb6k0Nup98qHg4p0RpZaTzVaLkhc1DDY0/pub?gid=951755148&single=true&output=csv\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.133.139, 74.125.133.101, 74.125.133.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.133.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://doc-0k-6k-sheets.googleusercontent.com/pub/l5l039s6ni5uumqbsj9o11lmdc/gvbkn7eki76msn2imm0bb5oj5k/1608655295000/114833318317024563176/*/e@2PACX-1vRPJMu_aen9BTSuW0tDJsbA07ZJBzJHeF2uM8Ov-GKhrT1rb6k0Nup98qHg4p0RpZaTzVaLkhc1DDY0?gid=951755148&single=true&output=csv [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-12-22 16:41:36--  https://doc-0k-6k-sheets.googleusercontent.com/pub/l5l039s6ni5uumqbsj9o11lmdc/gvbkn7eki76msn2imm0bb5oj5k/1608655295000/114833318317024563176/*/e@2PACX-1vRPJMu_aen9BTSuW0tDJsbA07ZJBzJHeF2uM8Ov-GKhrT1rb6k0Nup98qHg4p0RpZaTzVaLkhc1DDY0?gid=951755148&single=true&output=csv\n",
            "Resolving doc-0k-6k-sheets.googleusercontent.com (doc-0k-6k-sheets.googleusercontent.com)... 64.233.184.132, 2a00:1450:400c:c0b::84\n",
            "Connecting to doc-0k-6k-sheets.googleusercontent.com (doc-0k-6k-sheets.googleusercontent.com)|64.233.184.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘pub?gid=951755148&single=true&output=csv.1’\n",
            "\n",
            "pub?gid=951755148&s     [ <=>                ]  33.92K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2020-12-22 16:41:36 (4.57 MB/s) - ‘pub?gid=951755148&single=true&output=csv.1’ saved [34738]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb2AppotwUQd"
      },
      "source": [
        "#### Creating a Pandas DataFrame from Screaming Frog data\n",
        "\n",
        "\n",
        "Following the file structure generated using the Screaming Frog's crawler, we will use the following columns:\n",
        "\n",
        "- *url* (`cols='0'` | `Address`), \n",
        "- *http status* (`cols='2'` | `Status Code`), \n",
        "- *meta description lenght* (`cols='11'` | `Meta Description 1 Length`),\n",
        "- *position* (`cols='48'` | `Position`),\n",
        "\n",
        "We will then use *http status* to focus our analysis only to urls responding with `HTTP 200`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyPnprLnxXCP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "c044c8f0-7239-4fcb-a948-046685311b30"
      },
      "source": [
        "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vRPJMu_aen9BTSuW0tDJsbA07ZJBzJHeF2uM8Ov-GKhrT1rb6k0Nup98qHg4p0RpZaTzVaLkhc1DDY0/pub?gid=951755148&single=true&output=csv', # Update the string here to change the file\n",
        "                 #usecols=[0,2,11,48],  \n",
        "                 usecols=[0,2,11],\n",
        "                 header=0,\n",
        "                 encoding=\"utf-8-sig\" ) \n",
        "\n",
        "print(\"we have a total of:\", len(df), \" urls\")\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "we have a total of: 50  urls\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Address</th>\n",
              "      <th>Status Code</th>\n",
              "      <th>Meta Description 1 Pixel Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/will-on-wine...</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.thebrewery.co.uk/category/blog/pag...</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/londons-call...</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/tips-from-bl...</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/how-to-plan-...</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Address  ...  Meta Description 1 Pixel Width\n",
              "0  https://www.thebrewery.co.uk/blog/will-on-wine...  ...                               0\n",
              "1  https://www.thebrewery.co.uk/category/blog/pag...  ...                               0\n",
              "2  https://www.thebrewery.co.uk/blog/londons-call...  ...                               0\n",
              "3  https://www.thebrewery.co.uk/blog/tips-from-bl...  ...                               0\n",
              "4  https://www.thebrewery.co.uk/blog/how-to-plan-...  ...                               0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqnuyDjZyKfT"
      },
      "source": [
        "#### Finding all URLs where meta description are missing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKn4dAAGyPB2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "7114a03a-c4ce-4309-f057-bcd00103f32a"
      },
      "source": [
        "# Keep all rows representing a page with status = 200, with md 0, from the Italian blog and with Position < 15 \n",
        " \n",
        "#df = df[(df['Status Code'] == 200) & ((df['Meta Description 1 Pixel Width']== 0)) & (df['Address'].str.contains(\"blog/it\")) & (df['Position'] < 15) & (df['Position'] > 3)] # Use this with Screaming Frog\n",
        "\n",
        "df = df[(df['Status Code'] == 200) & \n",
        "        ((df['Meta Description 1 Pixel Width']== 0))\n",
        "        ] # Use this with Screaming Frog\n",
        "\n",
        "\n",
        "print(\"we have to process:\", len(df), \" urls\")\n",
        "\n",
        "# Reindex df\n",
        "df.index = range(len(df.index))\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "we have to process: 50  urls\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Address</th>\n",
              "      <th>Status Code</th>\n",
              "      <th>Meta Description 1 Pixel Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/will-on-wine...</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.thebrewery.co.uk/category/blog/pag...</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/londons-call...</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/tips-from-bl...</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/how-to-plan-...</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Address  ...  Meta Description 1 Pixel Width\n",
              "0  https://www.thebrewery.co.uk/blog/will-on-wine...  ...                               0\n",
              "1  https://www.thebrewery.co.uk/category/blog/pag...  ...                               0\n",
              "2  https://www.thebrewery.co.uk/blog/londons-call...  ...                               0\n",
              "3  https://www.thebrewery.co.uk/blog/tips-from-bl...  ...                               0\n",
              "4  https://www.thebrewery.co.uk/blog/how-to-plan-...  ...                               0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ2rVSKy2MWB"
      },
      "source": [
        "## Summarizing \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcD42IUDqlYb"
      },
      "source": [
        "## Running the analysis \n",
        "\n",
        "In the next cells we have one function called `url_to_string` to get the text from a URL (make sure to fine-tune this one if you know the class that contains the body of the article on your website) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-NV-LUQqy1u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5e62e019-d550-4eb9-af9b-54798e4494c3"
      },
      "source": [
        "# Get clean text from URL\n",
        "\n",
        "def url_to_string(url):\n",
        "  try:\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'}\n",
        "    res = requests.get(url, headers=headers)\n",
        "    html = res.text\n",
        "    soup = BeautifulSoup(html, 'html5lib')\n",
        "    for script in soup([\"script\", \"style\", 'aside']):\n",
        "        script.extract()\n",
        "    \n",
        "    # uncomment the lines in the if/else block and comment the one after if you know the name of the class containing the article body \n",
        "  #MK Changing the class name from 'entry-content' to 'post-body' and testing the output\n",
        "  #  if isinstance(soup.find('div', {'class' :'entry-content'}), type(None)): # here is the div containing the content\n",
        "\n",
        "    #MK Changing the class name from 'entry-content' to 'post-body' and testing the output\n",
        "    if isinstance(soup.find('div', {'class' :'post-body'}), type(None)): # here is the div containing the content\n",
        "      return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))\n",
        "    else:\n",
        "      return \" \".join(re.split(r'[\\n\\t]+', soup.find('div', {'class' :'post-body'}).text))   \n",
        "\n",
        "     # return \" \".join(re.split(r'[\\n\\t]+', soup.find('div', {'class' :'entry-content'}).text))   \n",
        "\n",
        "  except requests.exceptions.HTTPError as err:\n",
        "    print(err)\n",
        "    sys.exit(1)\n",
        "    return err\n",
        "\n",
        "'''\n",
        "# Get clean text from URL using Trafilatura\n",
        "\n",
        "def url_to_string(url):\n",
        "  try:\n",
        "    downloaded = trafilatura.fetch_url(url)\n",
        "    if downloaded is not None: # assuming the download was successful\n",
        "      result = trafilatura.extract(downloaded, include_tables=False, include_formatting=False, include_comments=False) \n",
        "    return result\n",
        "  except ValueError as err:\n",
        "    print(err)\n",
        "    sys.exit(1)\n",
        "    return err\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Get clean text from URL using Trafilatura\\n\\ndef url_to_string(url):\\n  try:\\n    downloaded = trafilatura.fetch_url(url)\\n    if downloaded is not None: # assuming the download was successful\\n      result = trafilatura.extract(downloaded, include_tables=False, include_formatting=False, include_comments=False) \\n    return result\\n  except ValueError as err:\\n    print(err)\\n    sys.exit(1)\\n    return err\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hp_UN8x14nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ece9a3d-e881-4cf3-9398-5d646cbc7387"
      },
      "source": [
        "# Create a list to store the MDs\n",
        "data_x = [] \n",
        "\n",
        "from summarizer import Summarizer\n",
        "# For each URL in the input CSV run the analysis and store the results in the list \n",
        "for i in range(len(df)):\n",
        "    # Here is the URL to be analyzed\n",
        "    line = df.iloc[i][0]\n",
        "\n",
        "\t# Error handling for HTTP connection problems\n",
        "    try:\n",
        "       body = url_to_string(line)\n",
        "    except:\n",
        "    \tprint('error while fetching', line, err)\n",
        "    \n",
        "\t# BERT\n",
        "    print(\"Summarizing URL via BERT: \" + line)\n",
        "    model = Summarizer()\n",
        "   #MK: Adding maxlength=250 \n",
        "   # result = model(body, min_length=60, ratio=0.005)\n",
        "    result = model(body, min_length=60, max_length=250, ratio=0.005)\n",
        "   \n",
        "    full = ''.join(result)\n",
        "    print(full)\n",
        "\n",
        "\t# Storing all values into the list \n",
        "    data_x.append({\"url\":line, \"BERT\":full})\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/will-on-wine-a-guide-to-supermarket-wines/\n",
            "As we are currently doing all our wine drinking at home, we wanted to find out what we should be looking for when heading to the shops to pick up our social distanced vino. For me, New World wine (Australia, New Zealand, Chile, Argentina and USA) still offer better value for money than the same priced French or Italian equivalent, particularly the well know French areas such as Bordeaux or Burgundy.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/category/blog/page/4/\n",
            "The Brewery was in the driver’s seat for Amazon Prime’s launch of The Grand Tour Season Three. We played host to a spectacular event to mark the launch of the new season.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/londons-calling-case-study/\n",
            "However, there is a lot of confusion about the best way to deliver these, and what tech to use.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/tips-from-blake-ezra-award-winning-photographer/\n",
            "We’ve asked Blake Ezra, a firmly established and very talented photographer who’s been to The Brewery many times, to give us some tips (photography tips but not only!) Whether that be for the sake of photography (having some beautiful shots as a couple) or simply to step back and enjoy each other’s company for a short time away from guests, it’s important to make that time.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/how-to-plan-a-royal-wedding-of-your-own/\n",
            "In just a matter of days, on Saturday 19th May, people all around the world will be tuning in to watch Prince Harry and Meghan Markle tie the knot in what will undoubtedly be a lavish affair at St George’s Chapel in Windsor. However the wedding of Harry and Meghan plays out, there’s absolutely no doubt that the occasion will be a spectacular one, much like royal weddings of the past.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/eight-of-the-most-captivating-speeches-ever/\n",
            "“According to most studies, people’s number one fear is public speaking. Her speech at the Conservative party conference in Brighton on October 10, 1980 – one year after being elected the UK’s first and only female Prime Minister – is a great example.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/what-we-learnt-from-the-latest-knowledge-guild/\n",
            "We always enjoy hosting #KnowledgeGuild with Speakers Corner and last week was no different, with amazing speakers including Brendan Hall, Maggie Alphonsi, Sally Bundock and Ed Stafford taking to the stage. The more we acknowledge Imposter Syndrome, whether in our professional or personal lives, the less affected we will be by those sneaky self-doubts.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/three-tips-to-help-bosses-throw-a-great-office-christmas-party/\n",
            "An awful one and it’s hard to control the damage to your reputation. Pace yourselves As a gesture of goodwill, and to prove you’re not a Scrooge, you might decide to close the office early on the day of the Christmas party.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/great-british-food/\n",
            "Executive Chef Tom Gore features in this months Great British Food magazine and you can read all about his famous Jacob’s Ladder Lasagne right here.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/christmas-parties-2019-the-goodnight-cabaret/\n",
            "We were overwhelmed with the success and popularity of last years Christmas party theme, our tribute to 1960s Las Vegas, ‘The Golden Palms Lounge and Casino’ and want to extend our thanks to the 26,000 people who partied with us. Some dismissed it as nothing more than an urban legend told as a whimsical reminder of better times, but there were others who knew they were not of this earth.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/supplier-spotlight-satureyes-my-favourite-photos/\n",
            "During lockdown we’ve taken the opportunity to speak to some of our favourite suppliers and quiz them about working at The Brewery. Like I said at the start, when you have the foundations it makes my life as a photographer and videographer a heck of a lot easier to get some of my most memorable shots.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/speakers-corner-at-the-brewery/\n",
            "In association with our friends at Speakers Corner we recently hosted an engaging and informative evening focusing on Innovation for the 21st century. The event was hosted by Kate Silverton and we heard from 3 amazing speakers who kept the audience gripped throughout.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/the-brewery-and-speakers-corner-get-technical-with-knowledge-guild-the-incredible-power-of-technology-brought-to-life/\n",
            "On Monday 17th February, The Brewery and Speakers Corner opened its doors for the latest installment of the highly anticipated Knowledge Guild series at the Chiswell Street venue. The 160-strong audience were treated to personal stories on everything from AI, voice and wearable technology, to robotics and prosthetics, as speakers discussed the ways in which they have harnessed technology to transform their ideas into reality.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/what-you-need-for-the-ideal-office-christmas-party/\n",
            "The annual Christmas party is a work tradition, and a great opportunity to raise everyone’s spirits. In this article The Brewery’s Creative Director, Simon Lockwood, explains how you could throw a festive do for your employees that will be remembered fondly all year long.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/keeping-you-safe-the-brewery-is-accredited-with-aim-secure/\n",
            "We’re still waiting for the all clear to get back to hosting events, but we are working tirelessly behind the scenes to make sure the venue is safe and secure for all of guests, staff and suppliers.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/the-goodnight-cabaret-in-pictures/\n",
            "The Goodnight Cabaret is The Brewery’s Christmas party theme for 2019 and we are very excited to be able to reveal what guests can expect to see if you book your party with us.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/amazon-prime-the-grand-tour-season-three-launch/\n",
            "On 15th January 2019, Amazon Prime hosted its Grand Tour Season Three launch at The Brewery, a venue in the heart of the city of London. The 18th century cobbled Courtyard was used for the arrival of guests; each of the presenters drove a car into the Courtyard and there was an area for press photographers and fans to stand and take photos.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/world-cup-2018-screenings/\n",
            "It’s World Cup year and we are already getting our hopes up for an England win, this is the year, we can feel it! We have a selection of spaces available for hire that can host parties from 30 – 700 guests, the packages are all inclusive and you can see what is included below.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/bio-sculpture-gb-visit-the-golden-palms-lounge-and-casino/\n",
            "On the 2nd December 2018, we were honored to be able to host Bio Sculpture’s 20th Anniversary party.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/wedding-trends-2015/\n",
            "If you are planning a wedding for 2015, then you’ve probably already trawled the internet for the most up-to-date and unique touches for your nuptials. With the ever-increasing popularity of wedding blogs, couples are seeing that it’s okay to go their own way with every aspect of their day,” she said. “\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/playtech-ice-2016-afterparty/\n",
            "We consulted with Playtech to create a bespoke food and cocktail menu which was served from a custom built bar and food stalls.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/london-technology-week-2015-celebrations-the-brewery/\n",
            "The technology sector has fast become the beating heart of London, bringing more financial investment during Q1 2015 than in any previous quarter. The new figures and record year-on-year visitor numbers continue to attract tech investors to our capital like never before, it’s not surprising that this year’s London Technology Week 2015 is going to be the biggest and best yet.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/shining-a-spotlight-on-mental-health/\n",
            "Throughout these challenging times our mental health is being affected more than ever, and it’s important to realise we’re not alone and that help is out there. We are noticing depression and anxiety in particular are on the rise, largely due to the effects of lockdown.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/case-study-amazon-prime-the-grand-tour-season-launch/\n",
            "The Brewery was in the driver’s seat for Amazon Prime’s launch of The Grand Tour Season Three. We played host to a spectacular event to mark the launch of the new season.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/fifi-uk-fragrance-awards-17th-may-2012-a-behi/\n",
            "Take a look at the video below to discover more about what goes on during a high profile event at The Brewery. “ Known as the ‘Oscars’ of the fragrance industry, the 20th Annual FiFi Awards 2012 took place at one of London’s most popular venues — The Brewery on Chiswell Street.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/the-brewery-showcases-its-catering-prowess-with-al-fresco-dinner-and-foraging-dessert/\n",
            "On Thursday 31 July, award-winning London events venue The Brewery got the summer season in full swing with a scrumptious evening of feasting and surprises for more than 140 industry professionals. Finally, guests were led into The Brewery’s newest hide away, The Grubstreet Author, where espresso martinis, amaretto sours and gimlets were served by the talented team of mixologists.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/a-look-inside-the-clandestine-club/\n",
            "We have posted exclusive pictures and videos of The Clandestine Club, The Brewery’s 2011 Christmas theme, on our Facebook, Flickr and YouTube pages. The links are posted below take a look and let us know what you think, and if you like what you see gives us a call and we can tell you all about what we have in store for 2012.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/the-brewery-roadshow-showcase/\n",
            "We’re hosting a roadshow showcase on Thursday 29th November from 9am – 2pm. There will be breakfast or lunch available to sample as well as the opportunity to see our amazing spaces set up as they would be for roadshows with a lovely gift bag to take away.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/food-drink/about/food-ethos/\n",
            "Our chefs works with their suppliers to earmark their best produce for The Brewery kitchen. Our menus reflect the seasons, so we keep food miles down and select ingredients according to what’s growing in local fields.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/introducing-the-electric-flamingo-lounge-and/\n",
            "This Christmas we will be taking a step back in time and celebrating 1980s Miami by recreating the infamous Electric Flamingo Lounge and Social Club. To learn more about what we are offering and the story behind The Electric Flamingo tune into: www.electric-flamingo.com\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/all-about-the-samba/\n",
            "Think of Brazil and you’ll probably picture hordes of elaborately dressed people dancing their way through the streets of Rio at Carnival time.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/case-study-udemy/\n",
            "The Brewery played host to innovation with an inspirational European summit. The Brewery has a reputation for being the go to venue for large or small tech conferences.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/brewery-speakers-corner-get-disruptive-knowledge-guild-game-changers-people-ideas-inventions-disrupted-world/\n",
            "Last night (Monday 26th February), The Brewery and Speakers Corner welcomed event professionals and budding disruptors to the first Knowledge Guild showcase event of 2018. At the end of all the Knowledge Guild events, guests and speakers share stories during a Q&A session, before delving into the post event reception and networking opportunity.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/getting-serious-about-coffee/\n",
            "We’re very excited to announce that after Easter will be serving ‘proper’ freshly ground coffee for all conferences.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/office-christmas-parties-at-brewery-london-2015/\n",
            "For London offices, it can be hard to think of a truly original Christmas party idea; most end up hiring out the same bar they go to every year. However, guests shouldn’t expect just your average masquerade ball; each gathering is themed, with previous events including the Fairytale of New York, Electric Flamingo and Dream Circus.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/avc-live-appointed-exclusive-in-house-av-and-event-production-partner-to-the-brewery/\n",
            "AVC is delighted to announce a five-year agreement with historic London venue The Brewery.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/venue-vendor-james-varah/\n",
            "The most recent Squaremeal Venue and Events magazine features an interview with our commercial director James Varah.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/spring-themed-weddings/\n",
            "Wedding and events planner, Jayne Mountford, and Executive chef, Steve Connell, have been sharing their thoughts on spring weddings with Vows and Venues Magazine. To avoid the unpredictability of the spring weather a simply themed marquee is not only practical, it’ll evoke a garden party-esque feeling that offers guests a change of scenery as well as the chance to enjoy the season in all its glory!\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/knowledge-guild-game-changers-people-ideas-inventions-disrupted-world/\n",
            "The first Knowledge Guild conference of the year saw us welcome a group of inspiring individuals who threw out the rule book and changed the game for the better.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/the-brewery-and-speakers-corner-rip-up-the-rule-book-at-knowledge-guild/\n",
            "On Monday evening, The Brewery and Speakers Corner welcomed more than 200 event professionals and entrepreneurs to the summer 2018 Knowledge Guild showcase. Last to take to the stage was Johnny Cupcakes who explained how to capture the imagination of future generations and create meaningful connections with consumers.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/christmas-parties-2020-enchantment-under-the-ocean/\n",
            "We are super excited about Christmas party season this year, as we will be heading back to 1950s America and becoming students at Chiswell Valley High. We know that you’re super busy hanging out at the diner trying to catch the eye of your perfect date, there is also the prom dress/tux to worry about and not to forget your speech if you are named Prom King or Queen.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/the-brewery-wins-big-at-the-london-tourism-awards/\n",
            "Last week, The Brewery celebrated success as they took home the award for Best Business Venue at the London Tourism Awards, hosted by London & Partners. The team are delighted that their hard work has been recognised, and look forward to welcoming guests to events at the venue in the future.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/the-brewery-and-speakers-corner-examine-the-power-of-diversity-at-knowledge-guild/\n",
            "On Monday evening (22 October), The Brewery and Speakers Corner welcomed more than 200 event professionals, thought leaders and entrepreneurs to the autumn 2018 Knowledge Guild showcase.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/brewery-powers-bloombergs-first-energy-summit/\n",
            "In October 2015, the inaugural Bloomberg New Energy Finance (BNEF) Future of Energy EMEA Summit took place at The Brewery.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/going-above-and-beyond-with-the-brewery-and-speakers-corner/\n",
            "Last night (22 February) The Brewery and Speakers Corner presented the first in its new series of Knowledge Guild conferences at the Chiswell Street venue. Sharing their incredible journeys from dreaming to achieving success, the 290 strong audience were treated to personal and professional stories of strength, leadership and teamwork.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/the-knowledge-guild-how-to-prepare-for-unprecedented-change/\n",
            "Yesterday’s installment (28 October) of The Knowledge Guild – our discussion series with Speaker’s Corner – even coined a new term, ‘Brexstay’, and welcomed the introduction of ‘Flextension’.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/six-things-avoid-doing-christmas-party/\n",
            "Christmas supposedly allows us the freedom to do things that at any other time of the year would be considered pretty much absolutely unacceptable. In reality, it’s possible to make a complete idiot of yourself if you misjudge your romantic revelations, especially if you’ve had a little Dutch courage.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/nothing-but-good-times-at-the-clandestine-clu/\n",
            "As part of our December 2011 Christmas party season we transformed The Brewery into the magnificent Clandestine Club. He looked after us very well and I would like you to thank him on our behalf – he also helped out on a couple of things that we were unprepared for.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/food-drink/chefs/recipes/\n",
            "The Brewery 52 Chiswell Street London, EC1Y 4SD Phone: 020 7638 8811 Email: info@thebrewery.co.uk ©The Brewery 2016 About Us Team CSR Awards Privacy Terms This website uses cookies to give you the best online experience.\n",
            "Summarizing URL via BERT: https://www.thebrewery.co.uk/blog/the-brewery-launches-forward-thinking-wine-range/\n",
            "As part of their green commitments, The Brewery has unveiled a selection of ‘Forward Thinking’ sustainable wines that love and look after the planet, celebrate female winemakers and are vegan friendly. The selection gives recognition for female winemakers and their skills and creativity for exploring exciting new flavours against the backdrop of a male-dominated industry.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p00mk90Szg6w"
      },
      "source": [
        "### Testing BERT Multilingual\n",
        "\n",
        "This cell is alternative to the cells above and will load a varian of BERT called `bert-base-multilingual-cased`.\n",
        "\n",
        "Trained on cased text in the top **104 languages** with the largest Wikipedias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifLNguJP0T8S"
      },
      "source": [
        "# Create a list to store the MDs\n",
        "data_x = [] \n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased', output_hidden_states=True)\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "from summarizer import Summarizer\n",
        "# For each URL in the input CSV run the analysis and store the results in the list \n",
        "for i in range(len(df)):\n",
        "    # Here is the URL to be analyzed\n",
        "    line = df.iloc[i][0]\n",
        "\n",
        "\t# Error handling for HTTP connection problems\n",
        "    try:\n",
        "       body = url_to_string(line)\n",
        "    except:\n",
        "    \tprint('error while fetching', line, err)\n",
        "    \n",
        "\t# BERT\n",
        "    print(\"Summarizing URL via BERT  ML: \" + line)\n",
        "    model = Summarizer(custom_model=bert_model, custom_tokenizer=bert_tokenizer)\n",
        "    #result = model(body, min_length=60, ratio=0.005)\n",
        "    result = model(body, min_length=60, max_length=155, ratio=0.005)\n",
        "    full = ''.join(result)\n",
        "    print(full)\n",
        "\n",
        "\t# Storing all values into the list \n",
        "    data_x.append({\"url\":line, \"BERT\":full})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNq3kDN3WRQt"
      },
      "source": [
        "### Testing the brand new ALBERT implementation\n",
        "\n",
        "This cell is alternative to the cell above and will load ALBERT (see: \"[ALBERT: A Lite BERT For Self-Supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942)\") "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7THygT5WPAL"
      },
      "source": [
        "# Create a list to store the MDs\n",
        "data_x = [] \n",
        "\n",
        "from transformers import AlbertTokenizer, AlbertModel\n",
        "\n",
        "albert_model = AlbertModel.from_pretrained('albert-base-v1', output_hidden_states=True)\n",
        "albert_tokenizer = AlbertTokenizer.from_pretrained('albert-base-v1')\n",
        "\n",
        "from summarizer import Summarizer\n",
        "# For each URL in the input CSV run the analysis and store the results in the list \n",
        "for i in range(len(df)):\n",
        "    # Here is the URL to be analyzed\n",
        "    line = df.iloc[i][0]\n",
        "\n",
        "\t# Error handling for HTTP connection problems\n",
        "    try:\n",
        "       body = url_to_string(line)\n",
        "    except:\n",
        "    \tprint('error while fetching', line, err)\n",
        "    \n",
        "\t# BERT\n",
        "    print(\"Summarizing URL via ALBERT: \" + line)\n",
        "    model = Summarizer(custom_model=albert_model, custom_tokenizer=albert_tokenizer)\n",
        "    result = model(body, min_length=60, ratio=0.005)\n",
        "    full = ''.join(result)\n",
        "    print(full)\n",
        "\n",
        "\t# Storing all values into the list \n",
        "    data_x.append({\"url\":line, \"BERT\":full})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZSEg-Bx61ea"
      },
      "source": [
        "## Storing data \n",
        "\n",
        "In the following cells we are going to save a CSV containing for each url the summaries generated by the different algos. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-46i_W868LU"
      },
      "source": [
        "# Save results to the output CSV\n",
        "df_new = pd.DataFrame(data_x, columns=[\"url\", \"BERT\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3eT90mn7oac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "224352d6-0874-4bde-faa1-5d2a7a7b5790"
      },
      "source": [
        "df_new.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>BERT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/will-on-wine...</td>\n",
              "      <td>As we are currently doing all our wine drinkin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.thebrewery.co.uk/category/blog/pag...</td>\n",
              "      <td>The Brewery was in the driver’s seat for Amazo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/londons-call...</td>\n",
              "      <td>However, there is a lot of confusion about the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/tips-from-bl...</td>\n",
              "      <td>We’ve asked Blake Ezra, a firmly established a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.thebrewery.co.uk/blog/how-to-plan-...</td>\n",
              "      <td>In just a matter of days, on Saturday 19th May...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url                                               BERT\n",
              "0  https://www.thebrewery.co.uk/blog/will-on-wine...  As we are currently doing all our wine drinkin...\n",
              "1  https://www.thebrewery.co.uk/category/blog/pag...  The Brewery was in the driver’s seat for Amazo...\n",
              "2  https://www.thebrewery.co.uk/blog/londons-call...  However, there is a lot of confusion about the...\n",
              "3  https://www.thebrewery.co.uk/blog/tips-from-bl...  We’ve asked Blake Ezra, a firmly established a...\n",
              "4  https://www.thebrewery.co.uk/blog/how-to-plan-...  In just a matter of days, on Saturday 19th May..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpapAYpp8Djw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cdcc9403-09d8-413a-a1da-928b2dda9e44"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# We set the variable forthe name of the CSV where we will store the new MDs \n",
        "outputcsv = 'new-md.csv'\n",
        "print(\"output csv name: \", outputcsv)\n",
        "\n",
        "df_new.to_csv(outputcsv, encoding='utf-8', index=False)\n",
        "print(\"Saving results on:\", outputcsv)\n",
        "files.download(outputcsv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output csv name:  new-md.csv\n",
            "Saving results on: new-md.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5a795f90-1bb8-44f4-91c1-626b7fc3eeef\", \"new-md.csv\", 17338)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqpldnPS-Q_0"
      },
      "source": [
        "# License\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Andrea Volpini, WordLift\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ]
    }
  ]
}